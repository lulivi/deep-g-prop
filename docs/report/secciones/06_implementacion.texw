\chapter{Implementación}

En este capítulo se explicará detalladamente la implementación en Python
seguida para llegar a las conclusiones obtenidas.

El código del trabajo está localizado en el directorio \texttt{src} situado en
la carpeta raíz del repositorio. El \textit{script} llamado
\texttt{deep\_g\_prop} es el punto de entrada del programa.

\section{Herramienta de línea de comandos}

Por línea de comandos se le indica la configuración que se quiere utilizar en
el algoritmo genético. Para información sobre las opciones del programa, se
puede ejecutar lo siguiente:

\begin{verbatim}
python src/deep-g-prop.py --help
\end{verbatim}

Lo cual mostraría por pantalla algo similar a:

{\footnotesize
\begin{verbatim}
Usage: deep_g_prop.py [OPTIONS]

Options:
  --dataset-name TEXT             name of the proben1 partition located in
                                  src/datasets/

  --hidden-layers-info HIDDEN LAYER INFO SEQUENCE
                                  sequence of hidden layer configuration in
                                  the form of "4 True, 2 False" to have two
                                  hidden layers: the first one trainable with
                                  4 neurons and the second one non-trainable
                                  with 2.

  --init-population-size INTEGER  number of individuals for the first
                                  population.

  --max-generations INTEGER       maximun number of generations.
  --cx-prob FLOAT                 probability for two individuals to mate.
  --mut-bias-prob FLOAT           probability to mutate each individual bias
                                  gene.

  --mut-weights-prob FLOAT        probability to mutate each individual weight
                                  gene.

  --mut-neuron-prob FLOAT         probability to add/remove the last neuron of
                                  a random layer for an individual.

  --mut-layer-prob FLOAT          probability to add/remove the last layer
                                  from an individual.

  --fit-train-prob FLOAT          probability to fit the training data for
                                  each individual in each evaluation.

  --verbosity [INFO|DEBUG]        stream handler verbosity level.
  --help                          Show this message and exit.
\end{verbatim}
}

Esta línea de comandos se ha construido usando el módulo
\textit{Click}\cite{py-click}. En ella se diferencian principalmente 10
opciones:

\begin{itemize}

    \item \code{--dataset-name} - nombre de la partición de datos a utilizar.

    \item \code{--hidden-layers-info} - secuencia de capas internas. Por
    ejemplo: \code{4 True, 2 False} sería una configuración con dos capas
    internas de 4 y 2 neuronas respectivamente en las que la primera capa es
    entrenable y la segunda no. Esto es, que la primera capa oculta recibirá
    mutaciones tanto en los pesos como en los sesgos y la segunda no.

    \item \code{--init-population-size} - tamaño de la población de individuos
    inicial.

    \item \code{--max-generations} - número máximo de generaciones que se
    ejecutará el algoritmo.

    \item \code{--cx-prob} - probabilidad que dos individuos se crucen entre
    sí.

    \item \code{--mut-bias-prob} - probabilidad que un individuo entrenable
    sufra modificaciones en cada gen de los conjuntos de sesgos.

    \item \code{--mut-weights-prob} - probabilidad que un individuo entrenable
    sufra modificaciones en cada gen de los conjuntos de pesos.

    \item \code{--mut-neuron-prob} - probabilidad que cada individuo de la
    población sufra un añadido / extracción de neurona en una capa aleatoria.

    \item \code{--mut-layer-prob} - probabilidad que cada individuo de la
    población sufra un añadido / extracción de última capa del modelo.

    \item \code{--fit-train-prob} - probabilidad que cada individuo de la población entrene previamente a la obtención de métricas.

\end{itemize}

También existe el comando \code{--verbosity} que define la verbosidad de la
terminal (a parte, se guardará toda la información de salida del algoritmo en
un archivo localizado en la carpeta \texttt{src/logs}) y \code{--help} que
muestra la salida antes mostrada.

\section{Utilidades}

Dentro de la carpeta donde se encuentra el código \texttt{src} podemos ver un
módulo llamado \textit{utils.py}. En este módulo se encuentran varias funciones
usadas varias veces de propósito general. Entre ellas se encuentran:

\begin{itemize}

  \item \code{read_proben1_partition} - como su propio nombre indica, carga los
  datos de una de las particiones de Proben1 y los devuelve como un conjunto de
  arrays multidimensionales de \textit{Numpy}\cite{py-numpy} para su cómoda
  utilización.

  \item \code{read_all_proben1_partitions} - obtiene todas las particiones de
  un mismo problema. Por ejemplo
  ``cancer'' obtendría las particiones ``cancer1'', ``cancer2'' y ``cancer3''.

  \item \code{print_table} - muestra una tabla de python de forma limpia y
  legible.

  \item \code{print_data_summary} - dada una partición de Proben1 muestra
  información util sobre ella, como el número de clases, la distribución de
  ejemplos entre ellas, etc.

\end{itemize}

Estas herramientas conceden facilidades para tener un código más limpio.

\section{Optimización con algoritmos genéticos}

El módulo más importante de código está situado en \texttt{src/ga\_optimization}
y alberga el algoritmo genético que evolucionará las configuraciones de
perceptrones multicapa elegidas.

Empezando por la unidad más pequeña de medida de un individuo, el gen está
definido en el contexto de pesos y sesgos de cada neurona. Cada individuo
compuesto por capas ocultas mas la externa externa y sus configuraciones está
inicializado a partir de distribuciones uniformes con valores en el rango
$[-1.0, 1.0]$. En la creación se le indica qué capas de las ocultas van a ser
entrenables, cuantos datos de entrada tendrá la red y cuántos datos de salida.
A parte, evidentemente, del número de neuronas de cada capa. Así, con una
semilla definida en \texttt{src/common} para permitir reproducibilidad es como
se construyen los individuos.

La definición de la función de evaluación es como sigue:

\begin{pycode}
def individual_evaluator(
    individual: MLPIndividual, trn: Proben1Split, tst: Proben1Split, **kwargs,
):
    """Evaluate an individual.

    :param individual: current individual to evaluate.
    :param trn: training data and labels.
    :param tst: validation data and labels.
    :param **kwargs: See below.
    :Keyword Arguments:
        - fit_train_prob: probability to fit the train data with some forward
            pases before predicting.
        - multi_class: ``True`` if the dataset is for multiclass
            classification.

    """
\end{pycode}

Teniendo el individuo, el conjunto que va a ser usado como entrenamiento, el
conjunto con el que se van a probar los datos y dos argumentos extra (la
probabilidad de ajuste previo y si el problema es de clasificación multiclase)
se calcula las medidas que se comentaron en el \autoref{chap:analysis}. La
primera parte de la función de evaluación consiste en construir un el modelo
dada la configuración del individuo. Dependiendo de la probabilidad de ajuste,
se entrenará el modelo o no.

\begin{pycode}
    multi_class = kwargs.get("multi_class", False)
    start_time = time.perf_counter()
    units_size_list = [
        layer.config["units"] for layer in individual.layers[:-1]
    ]
    DGPLOGGER.debug(
        f"    Evaluating individual with neuron number: {units_size_list}"
    )
    # Create the model with the individual configuration
    model = Sequential()

    for layer_index, layer in enumerate(individual.layers):
        model.add(Dense.from_config(layer.config))
        model.layers[layer_index].set_weights([layer.weights, layer.bias])

    model.compile(
        optimizer=SGD(),
        loss=CategoricalCrossentropy()
        if multi_class
        else BinaryCrossentropy(),
    )

    # Train if choosen
    if random.random() < kwargs.pop("fit_train_prob"):
        model.fit(
            trn.X, trn.y_cat, epochs=100, batch_size=16, verbose=0,
        )
\end{pycode}

Finalmente, tras la creación del modelo se procede a obtener las medidas
necesarias. Con los datos predichos, se obtienen la puntuación F2-score y el
porcentaje de error obtenido. También se muestra un resumen por pantalla.

\begin{pycode}
    # Predict the scores
    predicted_y = model.predict_classes(tst.X)
    f2_score = fbeta_score(
        tst.y,
        predicted_y,
        beta=2,
        average="micro" if multi_class else "binary",
    )
    accuracy = accuracy_score(tst.y, predicted_y, normalize=True)
    error_perc = (1.0 - accuracy) * 100
    end_time = time.perf_counter()
    DGPLOGGER.debug(
        f"        f2-score={f2_score:.5f}\n"
        f"        error%={error_perc:.2f}\n"
        f"        eval time={end_time - start_time: .2f} sec"
    )

    return (f2_score, error_perc)
\end{pycode}

A continuación se muestra un ejemplo de uso definiendo un individuo y
evaluándolo para el problema ``cancer1'':

<<term=False, evaluate=True>>=
from src.dgp_logger import DGPLOGGER
from src.ga_optimizer.toolbox import individual_evaluator
from src.ga_optimizer.types import HiddenLayerInfo, MLPIndividual
from src.utils import read_proben1_partition

DGPLOGGER.configure_dgp_logger("DEBUG")

dataset = read_proben1_partition("cancer1")
layer_sequence = [HiddenLayerInfo(4, True)]
individual = MLPIndividual(dataset.nin, layer_sequence, dataset.nout)

results = individual_evaluator(
    individual, dataset.trn, dataset.tst, fit_train_prob=1.0, multi_class=False
)
@

Una vez se configuradas las herramientas a utilizar (función de evaluación,
individuo, operaciones, función de adecuación...) y evaluada toda la población
inicial, se procede con el bucle central

\begin{algorithm}
    \caption{Genetic Algorithm loop}\label{alg:ga}
    \begin{algorithmic}[1]
        \State \textit{evaluate initial population}
        \While{\textit{max f2\_score less than one and there are generations left}}
            \If{\textit{max f2\_score hasn't improved in some generations}}
                \State \textit{Stop algorithm}
            \EndIf
            \State \textit{create an offspring from the population}
            \State \textit{apply crossover to the offspring}
            \State \textit{apply mutations to the offspring}
            \State \textit{replace the population with the modified offspring}
        \EndWhile
    \end{algorithmic}
\end{algorithm}

Se usa la medida de F2-score como centinela (a parte del número de generaciones
evidentemente) por si en algún momento se estanca el incremento de puntuación
se termine el algoritmo.

La función de cruce ocurre si se dan dos condiciones: que se cumpla la
probabilidad de cruce entre dos individuos, y que los dos individuos tengan la
misma forma\footnote{Mismo número de capas y neuronas en cada capa.}.

\begin{pycode}
def crossover_operator(ind1: MLPIndividual, ind2: MLPIndividual):
    """Apply crossover betweent two individuals.

    This method will swap a random neuron from a random layer. The neuron
    associated bias and weights are swapped.

    :param ind1: the first individual.
    :param ind2: the second individual.

    """
    layer_index = random.randint(0, len(ind1) - 1)
    neuron_index = random.randint(0, len(ind1.layers[layer_index].bias) - 1)

    (
        ind1.layers[layer_index].weights[:, neuron_index],
        ind2.layers[layer_index].weights[:, neuron_index],
    ) = (
        ind2.layers[layer_index].weights[:, neuron_index],
        ind1.layers[layer_index].weights[:, neuron_index],
    )
    (
        ind1.layers[layer_index].bias[neuron_index],
        ind2.layers[layer_index].bias[neuron_index],
    ) = (
        ind2.layers[layer_index].bias[neuron_index],
        ind1.layers[layer_index].bias[neuron_index],
    )
\end{pycode}

Obteniendo aleatoriamente la capa y la neurona que se va a intercambiar de
dicha capa se procede a intercambiar pesos y sesgos. En el siguiente código se
ve una muestra del funcionamiento.

<<term=False, evaluate=True>>=
import random

from src.dgp_logger import DGPLOGGER
from src.ga_optimizer.toolbox import crossover_operator
from src.ga_optimizer.types import HiddenLayerInfo, MLPIndividual
from src.utils import read_proben1_partition

DGPLOGGER.configure_dgp_logger("DEBUG")
random.seed(12345)

dataset = read_proben1_partition("cancer1")
individual_0 = MLPIndividual(dataset.nin, [], dataset.nout)
individual_1 = MLPIndividual(dataset.nin, [], dataset.nout)

w_0_before = individual_0.layers[0].bias.copy()
w_1_before = individual_1.layers[0].bias.copy()
print("\nBefore:")
print("Individual 0")
print(individual_0.layers[0].bias)
print("Individual 1")
print(individual_1.layers[0].bias)

crossover_operator(individual_0, individual_1)

w_0_after = individual_0.layers[0].bias.copy()
w_1_after = individual_1.layers[0].bias.copy()
print("\nAfter:")
print("Individual 0")
print(individual_0.layers[0].bias)
print("Individual 1")
print(individual_1.layers[0].bias)

print("\nComparison:")
print("Individual 0 before_bias == after_bias")
print(w_0_before == w_0_after)
print("Individual 1 before_bias == after_bias")
print(w_1_before == w_1_after)
@

Se observa efectivamente que los sesgos de la neurona 1 de la capa de salida se
han intercambiado por los del otro individuo.

Continuando con las operaciones encontramos las mutaciones. Existen 4 tipos de
mutaciones que se le aplican a los individuos:
