\chapter{Implementación}

En este capítulo se explicará detalladamente la implementación en Python
seguida para llegar a las conclusiones obtenidas.

El código del trabajo está localizado en el directorio \texttt{src} situado en
la carpeta raíz del repositorio. El \textit{script} llamado
\texttt{deep\_g\_prop} es el punto de entrada del programa.

\section{Herramienta de línea de comandos}

Por línea de comandos se le indica la configuración que se quiere utilizar en
el algoritmo genético. Para información sobre las opciones del programa, se
puede ejecutar lo siguiente:

\begin{verbatim}
python src/deep-g-prop.py --help
\end{verbatim}

Lo cual mostraría por pantalla algo similar a:

{\footnotesize
\begin{verbatim}
Usage: deep_g_prop.py [OPTIONS]

Options:
  --dataset-name TEXT             name of the proben1 partition located in
                                  src/datasets/

  --hidden-layers-info HIDDEN LAYER INFO SEQUENCE
                                  sequence of hidden layer configuration in
                                  the form of "4 True, 2 False" to have two
                                  hidden layers: the first one trainable with
                                  4 neurons and the second one non-trainable
                                  with 2.

  --init-population-size INTEGER  number of individuals for the first
                                  population.

  --max-generations INTEGER       maximun number of generations.
  --cx-prob FLOAT                 probability for two individuals to mate.
  --mut-bias-prob FLOAT           probability to mutate each individual bias
                                  gene.

  --mut-weights-prob FLOAT        probability to mutate each individual weight
                                  gene.

  --mut-neuron-prob FLOAT         probability to add/remove the last neuron of
                                  a random layer for an individual.

  --mut-layer-prob FLOAT          probability to add/remove the last layer
                                  from an individual.

  --fit-train-prob FLOAT          probability to fit the training data for
                                  each individual in each evaluation.

  --verbosity [INFO|DEBUG]        stream handler verbosity level.
  --help                          Show this message and exit.
\end{verbatim}
}

Esta línea de comandos se ha construido usando el módulo
\textit{Click}\cite{py-click}. En ella se diferencian principalmente 10
opciones:

\begin{itemize}

    \item \code{--dataset-name} - nombre de la partición de datos a utilizar.

    \item \code{--hidden-layers-info} - secuencia de capas internas. Por
    ejemplo: \code{4 True, 2 False} sería una configuración con dos capas
    internas de 4 y 2 neuronas respectivamente en las que la primera capa es
    entrenable y la segunda no. Esto es, que la primera capa oculta recibirá
    mutaciones tanto en los pesos como en los sesgos y la segunda no.

    \item \code{--init-population-size} - tamaño de la población de individuos
    inicial.

    \item \code{--max-generations} - número máximo de generaciones que se
    ejecutará el algoritmo.

    \item \code{--cx-prob} - probabilidad que dos individuos se crucen entre
    sí.

    \item \code{--mut-bias-prob} - probabilidad que un individuo entrenable
    sufra modificaciones en cada gen de los conjuntos de sesgos.

    \item \code{--mut-weights-prob} - probabilidad que un individuo entrenable
    sufra modificaciones en cada gen de los conjuntos de pesos.

    \item \code{--mut-neuron-prob} - probabilidad que cada individuo de la
    población sufra un añadido / extracción de neurona en una capa aleatoria.

    \item \code{--mut-layer-prob} - probabilidad que cada individuo de la
    población sufra un añadido / extracción de última capa del modelo.

    \item \code{--fit-train-prob} - probabilidad que cada individuo de la población entrene previamente a la obtención de métricas.

\end{itemize}

También existe el comando \code{--verbosity} que define la verbosidad de la
terminal (a parte, se guardará toda la información de salida del algoritmo en
un archivo localizado en la carpeta \texttt{src/logs}) y \code{--help} que
muestra la salida antes mostrada.

\section{Utilidades}

Dentro de la carpeta donde se encuentra el código \texttt{src} podemos ver un
módulo llamado \textit{utils.py}. En este módulo se encuentran varias funciones
usadas multiples veces de propósito general. Entre ellas se encuentran:

\begin{itemize}

  \item \code{read_proben1_partition} - como su propio nombre indica, carga los
  datos de una de las particiones de Proben1 y los devuelve como un conjunto de
  arrays multidimensionales de \textit{Numpy}\cite{py-numpy} para su cómoda
  utilización.

  \item \code{read_all_proben1_partitions} - obtiene todas las particiones de
  un mismo problema. Por ejemplo
  ``cancer'' obtendría las particiones ``cancer1'', ``cancer2'' y ``cancer3''.

  \item \code{print_table} - muestra una tabla de python de forma limpia y
  legible.

  \item \code{print_data_summary} - dada una partición de Proben1 muestra
  información util sobre ella, como el número de clases, la distribución de
  ejemplos entre ellas, etc.

\end{itemize}

\section{Optimización con algoritmos genéticos}

El módulo más importante de código está situado en \texttt{src/ga\_optimization}
y alberga el algoritmo genético que evolucionará las configuraciones de
perceptrones multicapa elegidas.

Empezando por la unidad más pequeña de medida de un individuo, el gen está
definido en el contexto de pesos y sesgos de cada neurona. Cada individuo
compuesto por capas ocultas mas la externa externa y sus configuraciones está
inicializado a partir de distribuciones uniformes con valores en el rango
$[-1.0, 1.0]$. En la creación se le indica qué capas de las ocultas van a ser
entrenables, cuantos datos de entrada tendrá la red y cuántos datos de salida.
A parte, evidentemente, del número de neuronas de cada capa. Así, con una
semilla definida en \texttt{src/common} para permitir reproducibilidad es como
se construyen los individuos.

La definición de la función de evaluación es como sigue:

\begin{minted}{python}
def individual_evaluator(
    individual: MLPIndividual, trn: Proben1Split, tst: Proben1Split, **kwargs,
):
    """Evaluate an individual.

    :param individual: current individual to evaluate.
    :param trn: training data and labels.
    :param tst: validation data and labels.
    :param **kwargs: See below.
    :Keyword Arguments:
        - fit_train_prob: probability to fit the train data with some forward
            pases before predicting.
        - multi_class: ``True`` if the dataset is for multiclass
            classification.

    """
\end{minted}

Teniendo el individuo, el conjunto que va a ser usado como entrenamiento, el
conjunto con el que se van a probar los datos y dos argumentos extra (la
probabilidad de ajuste previo y si el problema es de clasificación multiclase)
se calcula las medidas que se comentaron en el \autoref{chap:analysis}. La
primera parte de la función de evaluación consiste en construir un el modelo
dada la configuración del individuo. Dependiendo de la probabilidad de ajuste,
se entrenará el modelo o no.

\begin{minted}{python}
    multi_class = kwargs.get("multi_class", False)
    start_time = time.perf_counter()
    units_size_list = [
        layer.config["units"] for layer in individual.layers[:-1]
    ]
    DGPLOGGER.debug(
        f"    Evaluating individual with neuron number: {units_size_list}"
    )
    # Create the model with the individual configuration
    model = Sequential()

    for layer_index, layer in enumerate(individual.layers):
        model.add(Dense.from_config(layer.config))
        model.layers[layer_index].set_weights([layer.weights, layer.bias])

    model.compile(
        optimizer=SGD(),
        loss=CategoricalCrossentropy()
        if multi_class
        else BinaryCrossentropy(),
    )

    # Train if chosen
    if random.random() < kwargs.pop("fit_train_prob"):
        model.fit(
            trn.X, trn.y_cat, epochs=100, batch_size=16, verbose=0,
        )
\end{minted}

Finalmente, tras la creación del modelo se procede a obtener las medidas
necesarias. Con los datos predichos, se obtienen la puntuación F2-score y el
porcentaje de error obtenido. También se muestra un resumen por pantalla y el
tiempo que ha llevado calcular las puntuaciones.

\begin{minted}{python}
    # Predict the scores
    predicted_y = model.predict_classes(tst.X)
    f2_score = fbeta_score(
        tst.y,
        predicted_y,
        beta=2,
        average="micro" if multi_class else "binary",
    )
    accuracy = accuracy_score(tst.y, predicted_y, normalize=True)
    error_perc = (1.0 - accuracy) * 100
    end_time = time.perf_counter()
    DGPLOGGER.debug(
        f"        f2-score={f2_score:.5f}\n"
        f"        error%={error_perc:.2f}\n"
        f"        eval time={end_time - start_time: .2f} sec"
    )

    return (f2_score, error_perc)
\end{minted}

A continuación se muestra un ejemplo de uso definiendo un individuo y
evaluándolo para el problema ``cancer1'':

<<term=False, evaluate=True>>=
from src.dgp_logger import DGPLOGGER
from src.ga_optimizer.toolbox import individual_evaluator
from src.ga_optimizer.types import HiddenLayerInfo, MLPIndividual
from src.utils import read_proben1_partition

DGPLOGGER.configure_dgp_logger("DEBUG")

dataset = read_proben1_partition("cancer1")
layer_sequence = [HiddenLayerInfo(4, True)]
individual = MLPIndividual(dataset.nin, layer_sequence, dataset.nout)

results = individual_evaluator(
    individual, dataset.trn, dataset.tst, fit_train_prob=1.0, multi_class=False
)
@

Una vez se configuradas las herramientas a utilizar (función de evaluación,
individuo, operaciones, función de adecuación...) y evaluada toda la población
inicial, se procede con el bucle central

\begin{algorithm}
    \caption{Genetic Algorithm loop}\label{alg:ga}
    \begin{algorithmic}[1]
        \State \textit{evaluate initial population}
        \While{\textit{max f2\_score less than one and there are generations left}}
            \If{\textit{max f2\_score hasn't improved in some generations}}
                \State \textit{Stop algorithm}
            \EndIf
            \State \textit{select the offspring from the population}
            \State \textit{apply crossover to the offspring}
            \State \textit{apply mutations to the offspring}
            \State \textit{replace the population with the modified offspring}
        \EndWhile
    \end{algorithmic}
\end{algorithm}

Se usa la medida de F2-score como centinela (a parte del número de generaciones
evidentemente) por si en algún momento se estanca el incremento de puntuación
se termine el algoritmo.

Primero se selecciona la descendencia que será cruzada y mutada con la función
de selección: mediante torneos de tres individuos elegidos aleatoriamente de la
población, el mejor de ellos ocupará un lugar en la nueva descendencia.

La función de cruce ocurre si se dan dos condiciones: que se cumpla la
probabilidad de cruce entre dos individuos, y que los dos individuos tengan la
misma forma\footnote{Mismo número de capas y neuronas en cada capa.}.

\begin{minted}{python}
def crossover_operator(ind1: MLPIndividual, ind2: MLPIndividual):
    """Apply crossover betweent two individuals.

    This method will swap a random neuron from a random layer. The neuron
    associated bias and weights are swapped.

    :param ind1: the first individual.
    :param ind2: the second individual.

    """
    layer_index = random.randint(0, len(ind1) - 1)
    neuron_index = random.randint(0, len(ind1.layers[layer_index].bias) - 1)

    (
        ind1.layers[layer_index].weights[:, neuron_index],
        ind2.layers[layer_index].weights[:, neuron_index],
    ) = (
        ind2.layers[layer_index].weights[:, neuron_index],
        ind1.layers[layer_index].weights[:, neuron_index],
    )
    (
        ind1.layers[layer_index].bias[neuron_index],
        ind2.layers[layer_index].bias[neuron_index],
    ) = (
        ind2.layers[layer_index].bias[neuron_index],
        ind1.layers[layer_index].bias[neuron_index],
    )
\end{minted}

Obteniendo aleatoriamente la capa y la neurona que se va a intercambiar de
dicha capa se procede a intercambiar pesos y sesgos. En el siguiente código se
ve una muestra del funcionamiento.

<<term=False, evaluate=True>>=
import random

from src.dgp_logger import DGPLOGGER
from src.ga_optimizer.toolbox import crossover_operator
from src.ga_optimizer.types import HiddenLayerInfo, MLPIndividual
from src.utils import read_proben1_partition

DGPLOGGER.configure_dgp_logger("DEBUG")
random.seed(12345)

dataset = read_proben1_partition("cancer1")
individual_0 = MLPIndividual(dataset.nin, [], dataset.nout)
individual_1 = MLPIndividual(dataset.nin, [], dataset.nout)

w_0_before = individual_0.layers[0].bias.copy()
w_1_before = individual_1.layers[0].bias.copy()
print("\nBefore:")
print("Individual 0")
print(individual_0.layers[0].bias)
print("Individual 1")
print(individual_1.layers[0].bias)

crossover_operator(individual_0, individual_1)

w_0_after = individual_0.layers[0].bias.copy()
w_1_after = individual_1.layers[0].bias.copy()
print("\nAfter:")
print("Individual 0")
print(individual_0.layers[0].bias)
print("Individual 1")
print(individual_1.layers[0].bias)

print("\nComparison:")
print("Individual 0 before_bias == after_bias")
print(w_0_before == w_0_after)
print("Individual 1 before_bias == after_bias")
print(w_1_before == w_1_after)
@

Se observa efectivamente que los sesgos de la neurona 1 de la capa de salida se
han intercambiado por los del otro individuo.

Continuando con las operaciones encontramos las mutaciones. Existen 4 tipos de
mutaciones que se le aplican a los individuos:

\begin{itemize}

    \item Mutación de pesos: aplica ruido a un porcentaje de genes de los pesos
    de las capas del individuo.

    \item Mutación de sesgos: igual que el anterior, pero en vez de a los
    pesos, el ruido es aplicado a los genes de los sesgos de cada neurona.

    \item Mutación de neuronas: añade o elimina la última neurona de una capa
    oculta aleatoria.

    \item Mutación de capas: en este caso, añade o elimina una capa oculta al
    modelo. El número de neuronas y si se elimina o añade se calcula
    aleatoriamente.

\end{itemize}

Como la operación de mutación de pesos y sesgos es igual, hay que indicarle qué
atributo se quiere cambiar.

<<term=False, evaluate=True>>=
import numpy as np

from src.ga_optimizer.toolbox import weights_mutator, weights_mutator
from src.ga_optimizer.types import MLPIndividual
from src.utils import read_proben1_partition

np.random.seed(123)

dataset = read_proben1_partition("cancer1")
individual = MLPIndividual(dataset.nin, [], dataset.nout)
weights_before = individual.layers[0].weights.copy()

print("\nBefore mutation")
print(individual.layers[0].weights)

mutated_genes = weights_mutator(individual, "weights", 0.5)
weights_after = individual.layers[0].weights.copy()

print(f"\nAfter mutation of {mutated_genes} genes:")
print(individual.layers[0].weights)
print("\nComparison of weights difference:")
print(weights_after - weights_before)
@

La mutación de un porcentaje de genes en los pesos del individuo se ha
efectuado correctamente. El resto de genes, que da intacto (diferencia de 0).

En cuanto a la mutación de neuronas (añadido o eliminado de éstas en una capa
aleatoria), ocurre en dos fases: añadido/eliminado de neuronas de la capa
seleccionada y modificación del número de entradas de la siguiente capa. Como
comentábamos, se obtiene aleatoriamente qué capa vamos a modificar, y dentro de
la capa, si se va a añadir o eliminar una neurona:

\begin{minted}{python}
def neuron_mutator(individual: MLPIndividual) -> int:
    """Add/remove one neuron from a random hidden layer.

    Randomly choose whether to add or remove a neuron.

    :param individual: individual to mutate.
    :returns: whether the neuron was added or removed.

    """
    # We want to ignore output layer so it only adds/pops from a hidden layer
    layer_index = random.randint(0, len(individual) - 2)

    # Choose randomly to add or delete a neuron. If the number of neurons is
    # two, just add a new one.
    choice = (
        -1
        if len(individual.layers[layer_index].bias) <= 2
        else random.choice((-1, 1))
    )
\end{minted}

Si se realiza la opción de añadir neurona, primero se modifican los pesos y
sesgos añadiendo un nuevo elemento, generado con una distribución uniforme en
el rango $[-0.5, 0.5]$. Después se añade la nueva entrada a la capa siguiente.

\begin{minted}{python}
    if choice > 0:
        # Get previous layer neurons as a reference for creating a new neuron
        # for this layer
        previous_layer_neurons = individual.layers[layer_index].weights.shape[
            0
        ]
        # Append a new neuron to the weights and bias of the chosen layer
        individual.layers[layer_index].weights = np.append(
            individual.layers[layer_index].weights,
            np.random.uniform(-0.5, 0.5, (previous_layer_neurons, 1)),
            axis=1,
        )
        individual.layers[layer_index].bias = np.append(
            individual.layers[layer_index].bias,
            [random.uniform(-0.5, 0.5)],
            axis=0,
        )
        # Append a new input entry for the chosen layer in the following layer
        next_layer_neurons = len(individual.layers[layer_index + 1].bias)
        individual.layers[layer_index + 1].weights = np.append(
            individual.layers[layer_index + 1].weights,
            np.random.uniform(-0.5, 0.5, (1, next_layer_neurons)),
            axis=0,
        )
\end{minted}

Si por el contrario vamos a eliminar la última neurona de la capa, se eliminan
las entradas de los pesos y sesgos de la capa elegida y se quita la entrada
correspondiente en la capa siguiente.

\begin{minted}{python}
    else:
        # Remove last neuron weights and bias from the chosen layer
        individual.layers[layer_index].weights = np.delete(
            individual.layers[layer_index].weights, -1, axis=1
        )
        individual.layers[layer_index].bias = np.delete(
            individual.layers[layer_index].bias, -1, axis=0
        )
        # Remove the input neuron from the next layer
        individual.layers[layer_index + 1].weights = np.delete(
            individual.layers[layer_index + 1].weights, -1, axis=0
        )
\end{minted}

Finalmente actualizamos las configuraciones de la capa elegida y la siguiente,
y devolvemos si el cambio ha sido de añadir o eliminar neurona.

\begin{minted}{python}
    # Update the units in the chosen and next layer config
    individual.layers[layer_index].config["units"] += choice
    individual.layers[layer_index + 1].config["batch_input_shape"][1] += choice

    return choice
\end{minted}

En el siguiente código vemos el añadido y la eliminación de neuronas:

<<term=False, evaluate=True>>=
import random

from src.ga_optimizer.toolbox import neuron_mutator
from src.ga_optimizer.types import HiddenLayerInfo, MLPIndividual
from src.utils import read_proben1_partition

random.seed(12345)

dataset = read_proben1_partition("cancer1")
individual = MLPIndividual(
    dataset.nin, [HiddenLayerInfo(3, True)], dataset.nout
)

print("\nBefore first mutation. Weights and bias shapes:")
print(individual.layers[0].weights.shape, individual.layers[0].bias.shape)

neuron_change = neuron_mutator(individual)
result = "addition" if neuron_change > 0 else "substraction"

print(f"\nAfter the {result} of one neuron. Weights and bias shapes:")
print(individual.layers[0].weights.shape, individual.layers[0].bias.shape)

neuron_change = neuron_mutator(individual)
result = "addition" if neuron_change > 0 else "substraction"

print(f"\nAfter the {result} of one neuron. Weights and bias shapes:")
print(individual.layers[0].weights.shape, individual.layers[0].bias.shape)
@

Por último, existe la operación de mutar capas ocultas (eliminación y añadido).
Esta operación sólo puede modificar la última capa oculta del modelo, es decir,
añadir una nueva capa antes de la capa de salida, o eliminarla. Igual que se
hace en la mutación de neuronas primero se obtiene un número aleatorio en el
rango $[-1, 1]$ que decidirá si se añade o quita una capa. También se comprueba
si solo queda una capa, para entonces añadir obligatoriamente y no dar pie a
quitar esa única capa oculta.

\begin{minted}{python}
def layer_mutator(individual: MLPIndividual) -> int:
    """Add/remove one layer to the model.

    :param individual: individual to mutate.
    :return: wether the layer was added or removed.

    """
    # Choose randomly to add or delete a layer. Ensure there are 2 or more
    # layers in the model before deleting one. The output layer is included in
    # the count.
    choice = (
        1
        if len(individual) <= 2
        else random.choice((-1, 1))
    )

    difference = 0
\end{minted}

Lo que continúa se puede dividir en dos partes al igual que el operador de
neuronas. Primero se crea la capa nueva, con un número de neuronas aleatorio
dentro del rango $[2, 5]$. Esta información se usa para modificar la siguiente
capa: si por ejemplo teniendo la capa con forma $(9, 3)$ siendo $9$ las
neuronas de entrada de la capa y $3$ las propias de la capa, añadimos una capa
que tiene $5$ neuronas, la capa de salida tendría dos conexiones inexistentes.
Entonces hay ó que añadir neuronas de entrada (de forma similar a como se hace
en el operador de neuronas) en la siguiente capa, o eliminar las que quedan
huérfanas:

\begin{minted}{python}
    if choice > 0:
        # Choose a random number of neurons
        new_layer_output_neurons = random.randint(2, 5)
        # Obtain current last hidden layer neuron number
        previous_layer_output = individual.layers[-2].config["units"]
        # Insert a new hidden layer into the individual
        individual.append_hidden(
            Layer.uniform(
                name=f"Hidden{len(individual)}",
                input_neurons=previous_layer_output,
                output_neurons=new_layer_output_neurons,
                trainable=True,
            )
        )

        # Obtain the differences between the new layer neurons and the output
        # layer input neurons and apply necessary changes to this last one
        output_layer_input_neurons = individual.layers[-1].weights.shape[0]
        difference = new_layer_output_neurons - output_layer_input_neurons

        # Add input neuron entries
        if difference > 0:
            next_layer_neurons = len(individual.layers[-1].bias)
            individual.layers[-1].weights = np.append(
                individual.layers[-1].weights,
                np.random.uniform(-1.0, 1.0, (difference, next_layer_neurons)),
                axis=0,
            )
        # Remove input neuron entries
        elif difference < 0:
            individual.layers[-1].weights = np.delete(
                individual.layers[-1].weights,
                slice(
                    output_layer_input_neurons + difference,
                    output_layer_input_neurons,
                ),
                axis=0,
            )
\end{minted}

En segundo lugar, si por el contrario se ha decidido eliminar una capa hay que
obtener las neuronas de la capa anterior a la actual para después de eliminar
la última capa oculta, configurar correctamente la capa de salida:

\begin{minted}{python}
    else:
        # Obtain the predecessor output units and delte the chosen layer
        removed_predecessor_units = individual.layers[-3].config["units"]
        del individual.layers[-2]

        # Calculate the difference between the predecesor layer and the output
        # layer
        output_layer_input_len = individual.layers[-1].weights.shape[0]
        difference = removed_predecessor_units - output_layer_input_len

        # Append the neccesary input neuron entries
        if difference > 0:
            next_layer_neurons = len(individual.layers[-1].bias)
            individual.layers[-1].weights = np.append(
                individual.layers[-1].weights,
                np.random.uniform(-0.5, 0.5, (difference, next_layer_neurons)),
                axis=0,
            )
        # Remove the leftovers
        elif difference < 0:
            individual.layers[-1].weights = np.delete(
                individual.layers[-1].weights,
                slice(
                    output_layer_input_len + difference, output_layer_input_len
                ),
                axis=0,
            )
\end{minted}

Para finalizar, hay que modificar de nuevo la configuración de la capa de
salida y devolver el número de capas añadidas/eliminadas.

\begin{minted}{python}
    # Update output layer input neurons
    individual.layers[-1].config["batch_input_shape"][1] += difference

    return choice
\end{minted}

En el siguiente ejemplo se comprueba que efectivamente se añade y elimina la
última capa satisfactoriamente:

<<term=False, evaluate=True>>=
import random

from src.ga_optimizer.toolbox import layer_mutator
from src.ga_optimizer.types import HiddenLayerInfo, MLPIndividual
from src.utils import read_proben1_partition

random.seed(12345)

dataset = read_proben1_partition("cancer1")
individual = MLPIndividual(
    dataset.nin, [HiddenLayerInfo(3, True)], dataset.nout
)

print("\nBefore first mutatio. The hidden layers:")
print([layer.config["units"] for layer in individual.layers[:-1]])

layer_change = layer_mutator(individual)
result = "addition" if layer_change > 0 else "substraction"

print(f"\nAfter the {result} of one laye. The hidden layers:")
print([layer.config["units"] for layer in individual.layers[:-1]])

layer_change = layer_mutator(individual)
result = "addition" if layer_change > 0 else "substraction"

print(f"\nAfter the {result} of one laye. The hidden layers:")
print([layer.config["units"] for layer in individual.layers[:-1]])
@

A parte de todo lo nombrado anteriormente que es lo más destacable del código,
existen varias funciones de utilidades, como la de mostrar un resumen de las
puntuaciones de los individuos después de cada generación, presentar un resumen
general al terminar el algoritmo, evaluar el mejor individuo de la generación
inicial y la final, ... Además también se pueden encontrar funciones de apoyo
que permiten por ejemplo, cuando se va a mutar la población calcular con un
número aleatorio si se van a mutar las neuronas o las capas. Lo mismo ocurre
con el cruce entre individuos. Todo el código esta liberado bajo la licencia
GPLv3\cite{gplv3} y se puede encontrar en GitHub\cite{deep-g-prop}.
