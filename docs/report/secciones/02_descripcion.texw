\chapter{Descripción del problema} \label{chap:problem-description}

Como se introdujo en el capítulo anterior, las \textit{redes neuronales
artificiales} y en concreto los \textit{perceptrones multicapa} son un modelo
computacional inspirado en las \textit{neuronas} biológicas. Este modelo es muy
complejo dado que tiene una cantidad de parámetros configurables inmensa, como
el número de capas de la red, el número de \textit{neuronas} de cada capa, la
función de activación de cada \textit{neurona}... Lo cual conlleva a invertir
una cantidad ingente de tiempo para poder configurar manualmente la red acorde
al problema que se plantee.

En las siguientes secciones, se explicará de forma más detallada los
\textit{perceptrones multicapa} y los \textit{algoritmos genéticos}.

\section{Perceptrón multicapa}

Los \textit{perceptrones multicapa} son un tipo de \textit{redes neuronales}
simples. Éstos están compuestos de distintas capas: una de entrada, una de
salida y una o varias capas ocultas. Cada una a su vez está formada por un
numero fijo de \textit{neuronas} (ver \autoref{tikz:mlp}).

\begin{figure}[h!]
    \centering

    \caption{Diagrama de un perceptrón multicapa con cuatro \textit{neuronas}
    de entrada, dos de salida y dos capas ocultas con cinco \textit{neuronas}
    cada una.}\label{tikz:mlp}

    \vspace*{0.5cm}

    \begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=2.5cm]
        \tikzstyle{every pin edge}=[<-,shorten <=1pt]
        \tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,
        inner sep=0pt]
        \tikzstyle{input neuron}=[neuron, fill=green!50];
        \tikzstyle{output neuron}=[neuron, fill=red!50];
        \tikzstyle{hidden neuron}=[neuron, fill=gray!50];
        \tikzstyle{annot} = [text width=4em, text centered]

        % Draw the input layer nodes
        \foreach \id in {1,...,4}
        % This is the same as writing \foreach \name / \id in {1/1,2/2,3/3,4/4}
            \node[input neuron, label=left:{Input \#\id}] (I-\id) at (0,-\id) {};

        % Draw the hidden layers nodes
        \foreach \id in {1,...,5}
            \path[yshift=0.5cm]
                node[hidden neuron] (H1-\id) at (2.5cm,-\id cm) {};

        \foreach \id in {1,...,5}
            \path[yshift=0.5cm]
                node[hidden neuron] (H2-\id) at (4.5cm,-\id cm) {};

        % Draw the output layer nodes
        \foreach \id / \z in {1/2, 2/3, 3/4}
            \node[output neuron,label={right:Output \#\id}, right of=H2-\z]
                (O\id) {};

        % Connect every node in the input layer with every node in the first
        % hidden layer.
        \foreach \source in {1,...,4}
            \foreach \dest in {1,...,5}
                \path (I-\source) edge (H1-\dest);

        % Connect every node in the first hidden layer with every node in the
        % second hidden layer.
        \foreach \source in {1,...,5}
            \foreach \dest in {1,...,5}
                \path (H1-\source) edge (H2-\dest);

        % Connect every node in the hidden layer with the output layer
        \foreach \source in {1,...,5}
            \foreach \dest in {1,...,3}
                \path (H2-\source) edge (O\dest);

        % Annotate the layers
        \node[annot,above of=H1-1, node distance=1cm] (hl) {Hidden layer 1};
        \node[annot,above of=H2-1, node distance=1cm] (h2) {Hidden layer 2};
        \node[annot,left of=hl] {Input layer};
        \node[annot,right of=h2] {Output layer};
    \end{tikzpicture}% End of code

    \vspace*{0.5cm}

    \caption*{Versión modificada de un ejemplo de TEXample \cite{nn-diagram}.}
\end{figure}

Cada \textit{perceptrón} o \textit{neurona} tiene un valor de activación
(normalmente incluido en el rango $[0, 1]$). En la primera capa, éste viene
dado por los datos de entrada, como por ejemplo los píxeles de una imagen o las
características de un ejemplo. Los valores de activación de las
\textit{neuronas} de cada capa vienen dados por la siguiente función:

\[
a^{(L)}_{i} \equiv f(w^{(L)}_{0} a^{(L-1)}_{0} + w^{(L)}_{1} a^{(L-1)}_{1} +
\cdots + w^{(L)}_{i} a^{(L-1)}_{i} + \cdots + w^{(L)}_{n} a^{(L-1)}_{n} +
b^{(L)}_{i})
\]

ó

\[
a^{(L)}_{i} \equiv f(\sum_{j=0}^{n-1}(w^{(L)}_{j} a^{(L-1)}_{j}) + b^{(L)}_{i})
\]

\noindent donde $L$ es el índice de la capa, $i$ es el índice de la neurona
dentro de dicha capa, $w^{(L)}_{n}$ es el peso que hay en la conexión entre la
neurona $(L-1,j)$ y $(L,i)$, $b^{(L)}_{i}$ es el valor de sesgo que se le
aplica al resultado de la suma de la multiplicación de pesos por las
activaciones correspondientes y $f()$ es la función que define la activación de
cada neurona. Existen distintos tipos de funciones utilizadas en este punto,
como la lineal, sigmoide, rectificadora (ReLU), etc. La expresión anterior se
puede resumir así:

\[
a^{(L)} \equiv f(W a^{(L-1)} + b)
\]

\noindent donde $a^{(L)}$ es el vector de valores de activación de cada
\textit{neurona} en la capa $L$, $W$ es el vector de pesos de las uniones entre
la capa $L-1$ y $L$, $b$ es el vector de sesgos que se le aplica al resultado y
$f(x)$ es la función antes descrita.

Una vez evaluadas todas las capas, las \textit{neuronas} de la capa de salida,
éstas indican la certeza con la que el \textit{perceptrón multicapa} ha
predicho cada una de las clases del problema (generalmente en el rango
$[0.0, 1.0]$). En la \textit{clasificación supervisada} obteniendo el cuadrado
de la diferencia entre del vector de salidas (los valores de activación de las
\textit{neuronas} de la capa de salida) y lo etiquetado (valores que deberían
de haberse obtenido) se obtiene el costo de cada ejemplo (véase
\autoref{fig:mlp-cost}). Haciendo el promedio de todos estos valores de costo
se obtiene el costo global del modelo.

\begin{figure}[h!]
    \centering
    \caption{Obtención del coste de un ejemplo.}
    \label{fig:mlp-cost}
    \vspace*{0.5cm}
    \includegraphics{figures/MLP-cost.pdf}
\end{figure}

La forma óptima de mejorar el modelo es disminuyendo el costo ($C$), buscando
obtener valores mínimos ($C \approx 0$). El costo variará dependiendo de los
valores de los pesos correspondientes a cada union de \textit{neuronas} y los
sesgos correspondientes a cada función de activación. Una aproximación estándar
para llevar a cabo esta minimización se conoce como \textit{propagación hacia
atrás} (\textit{backpropagation}) y suele utilizar el algoritmo de gradiente
descendiente (o su variación estocástica), \textit{adam} (una variante del
gradiente descendiente estocástico) o \textit{lbfgs} (BFGS de memoria limitada)
entre otros. La fórmula con la que podemos describir el costo de todos los pesos
y sesgos sería la siguiente:

\[
C(w,b) \equiv \frac{1}{2n} \sum_{x} \parallel y(x) - a \parallel^{2}
\]

$w$ denota el conjunto de pesos de la \textit{red}, $b$ el de sesgos, $n$ es el
número total de ejemplos, $y(x)$ es el valor etiquetado del ejemplo y $a$ el
obtenido. La sumatoria es sobre todos los ejemplos de entrenamiento. Esta
función es conocida como \textit{error cuadrático medio} o \textit{MSE} (del
inglés) y como se comentó en el párrafo anterior se busca minimizarla y hacer
que $y(x)$ se aproxima a $a$ para todos los ejemplos de entrenamiento, ya que
significaría que todos los ejemplos (o casi todos) se clasifican bien dando
lugar a un modelo bien entrenado.

\section{Algoritmo genético}

Los \textit{algoritmos genéticos}\cite{ga-intro} son un unas metaheurísticas
que se inspiran en la selección natural, y que forman parte del grupo de los
\textit{algoritmos evolutivos}. Suelen utilizarse en problemas de optimización,
como el que se trata aquí. Las características más destacables de estas
metaheurísticas son sus funciones principales (ver \autoref{fig:ga-steps}):

\begin{itemize}

\item Iniciación de la población. La población está compuesta por cromosomas, y
estos a su vez por genes. En el caso de la optimización de parámetros para
\textit{perceptrones multicapa} podríamos considerar como genes: número de
capas ocultas, número de neuronas en cada capa, vectores de inicialización de
los pesos y los sesgos, función de activación...

\item Evaluación de la población. En esta etapa se comprueba la bondad de cada
elemento de la población, es decir, se utilizan los cromosomas de la población
para entrenar y testear redes neuronales y ver su rendimiento. Finalmente se
obtiene un resultado y se guarda con el cromosoma, que servirá para elegir la
siguiente población de individuos.

\item Selección. Se eligen los individuos para su cruce de dos en dos. Existen
varios métodos de selección, como la selección por torneo, por rango,
aleatorio, etc.

\item Cruce. Se obtienen nuevos individuos de la población (descendencia)
mezclando atributos de supervivientes tras la selección. Se puede mantener una
población estable teniendo descendencia hasta llegar al mismo número de
cromosomas del principio.

\item Mutación. En este último paso previo a la nueva evaluación se eligen
aleatoriamente cromosomas dentro de la población y se realizan ciertas
mutaciones en sus genes.

\end{itemize}

Hay que definir también un punto de parada, como un número fijo de iteraciones
o que se la mejora entre una población y otra sea menor de un umbral.

\begin{figure}[h!]
    \centering
    \caption{Diagrama del proceso de evolución de los algoritmos genéticos.}
    \label{fig:ga-steps}
    \vspace*{0.5cm}
    \includegraphics{figures/GA.pdf}
\end{figure}

Esta metaheurística se puede utilizar para solucionar nuestro problema
principal: optimización de hiperparámetros para los \textit{perceptrones
multicapa}. También existen otros métodos como \textit{grid search} o
\textit{random search}.
